import math
import numpy as np
import pandas as pd
import yfinance as yf  # This library automatically fetches stock data from Yahoo
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import Dense, LSTM
import matplotlib.pyplot as plt

# Getting the stock quote
df = yf.download('AAPL', start='2012-01-01', end='2019-12-17')
# Show the data
print(df.head())

# The number of rows and columns
print(df.shape)

# Visualizing Closing Price History
plt.figure(figsize=(16,8))
plt.title('Close Price History')
plt.plot(df['Close'])
plt.xlabel('Date', fontsize=18)
plt.ylabel('Close Price USD($)', fontsize=18)
plt.show()

# Creating a new dataframe with only the 'Close' column
dta = df[['Close']]  # Must use double brackets to correctly filter the 'Close' column
print("Filtered dataframe (dta) head: \n", dta.head())
print("Filtered dataframe (dta) shape: ", dta.shape)

# Convert dataframe to a numpy array
dataset = dta.values
print("Dataset shape: ", dataset.shape)  

# Get the number of rows to train the LSTM model on
training_data_len = math.ceil(len(dataset) * .8)
print("Training data length: ", training_data_len)

''' Scale the Data (as its good practise to apply preprocessing transformations,
such as scaling before its presented to a neural network '''

scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(dataset)

# Check the first few rows of the scaled data
print(scaled_data)

#Create the training data set 
#Create the scaled training data set
train_data = scaled_data[0:training_data_len,:]
#Split the data into x_train and y_train data sets
x_train =[]
y_train=[]

for i in range(60, len(train_data)):
    x_train.append(train_data[i-60:i,0])
    y_train.append(train_data[i,0])

    if i<=60:
        print(x_train)
        print(y_train)
        print()

